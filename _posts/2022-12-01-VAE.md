---
layout: post
title:  "Variational AutoeEncoder is not an AutoEncoder"
categories: [ AI, MachineLearning ]
image: assets/images/vae_main.png
---

# 계속 나오는 VAE! 공부해보자

해당 포스트는 이활석님의 "오토인코더의 모든 것"강의를 정리한 포스트입니다.

## contents

1. revisit DNN
2. manifold learning
3. AutoEncoder
4. Variational AutoEncoder
5. Application

## AutoEncoder

AutoEncoder는 인공신경망 네트워크의 일종으로, 차원축소를 목적으로 데이터의 representation을 학습하기 위한 네트워크이다.
최근에는 AE 모델이 generative model분야에서 자주 사용된다고 한다. (그 이유는 이따가 알아봅시다.)

## 오토인코더의 구조
![AE](https://user-images.githubusercontent.com/85322951/204951758-b1bfb407-8baa-4912-9b40-0130db790376.png)

오토인코더는 다음과 같이 인코더와 디코더가 붙어 있는 구조를 갖고 있다.
오토인코더를 학습할 때는 비지도학습을 따르고 loss는 negative Maximum Likelihood로 해석된다.(뒷부분에서 자세히 설명)
학습완료 후 인코더는 차원축소 모델로 기능하고 디코더는 생성모델로 기능한다.

AutoEncoder에 대한 키워드는 4가지로 볼 수가 있다.

1. Unsupervised learing : 비지도학습, 즉 학습시 라벨링이 필요가 없다!
2. manifold learning: 고차원의 공간 전체에 중요한 정보가 있는게 아니다. 정보가 몰려 있는 manifold 공간을 찾아 차원을 축소시키자.
3. generative model learning: 모델 내 생성파트가 존재한다.
4. Maximum Likelihood density estimation: 우도를 최대화하는 density를 예측한다.

autoencoder를 본격적으로 들어가기 전 먼저 필요한 DNN에 대한 이해를 해보도록 하자.

## revisit DNN

고전적 머신러닝의 방법론을 순서대로 생각해보자.  (비지도학습기준)
1. 먼저 데이터셋을 모은다. (X, y) 
2.  X를 가지고 y를 설명할 좋은 방법은 없을까? 가장 좋은 설명을 하는 model을 정의한다. 
$f_{theta}$
4.  



