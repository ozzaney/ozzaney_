---
layout: post
title:  "Variational AutoeEncoder is not an AutoEncoder"
categories: [ AI, MachineLearning ]
image: assets/images/vae_main.png
use_math: true
---

# 계속 나오는 VAE! 공부해보자

해당 포스트는 이활석님의 "오토인코더의 모든 것"강의를 정리한 포스트입니다.

## contents

1. revisit DNN
2. manifold learning
3. AutoEncoder
4. Variational AutoEncoder
5. Application

## AutoEncoder

AutoEncoder는 인공신경망 네트워크의 일종으로, 차원축소를 목적으로 데이터의 representation을 학습하기 위한 네트워크이다.
최근에는 AE 모델이 generative model분야에서 자주 사용된다고 한다. (그 이유는 이따가 알아봅시다.)

## 오토인코더의 구조
![AE](https://user-images.githubusercontent.com/85322951/204951758-b1bfb407-8baa-4912-9b40-0130db790376.png)

오토인코더는 다음과 같이 인코더와 디코더가 붙어 있는 구조를 갖고 있다.
오토인코더를 학습할 때는 비지도학습을 따르고 loss는 negative Maximum Likelihood로 해석된다.(뒷부분에서 자세히 설명)
학습완료 후 인코더는 차원축소 모델로 기능하고 디코더는 생성모델로 기능한다.

AutoEncoder에 대한 키워드는 4가지로 볼 수가 있다.

1. Unsupervised learing : 비지도학습, 즉 학습시 라벨링이 필요가 없다!
2. manifold learning: 고차원의 공간 전체에 중요한 정보가 있는게 아니다. 정보가 몰려 있는 manifold 공간을 찾아 차원을 축소시키자.
3. generative model learning: 모델 내 생성파트가 존재한다.
4. Maximum Likelihood density estimation: 우도를 최대화하는 density를 예측한다.

autoencoder를 본격적으로 들어가기 전 먼저 필요한 DNN에 대한 이해를 해보도록 하자.
(굳이 DNN에 대해서 다시 다루는 이유는 loss를 MLE관점에서 해석한다는 의미를 이해하기 위해서이다.)

## revisit DNN

고전적 머신러닝의 방법론을 순서대로 생각해보자. (비지도학습기준)
1. 먼저 데이터셋을 모은다. (X, y) 
2.  X를 가지고 y를 설명할 좋은 방법은 없을까? 가장 좋은 설명을 하는 model을 정의한다.
 $f_{\theta}()$
모델은 theta의 함수이다.
3. Loss는 target과 예측값의 차이이다. 원하는 Loss를 정의한다. 이때 Loss는 target과 model에 X를 대입한 값에 대한 함수이다.
4. learning 과정은 Loss를 최소화하는 $\theta$를 찾는 과정이다. 이때 closed form으로 argmin L이 주어지면 좋지만 그렇지 않을 경우 gradient descent 방법과 같은 iterative한 방법을 적용한다. 
5. 4번 과정을 통해 얻은 최적의 $\theta$를 f에 대입하여 최종 모델을 얻는다. model에 새로운 x데이터를 대입한 $f_{\theta}$가 $y_{new}$와 가까운지를 본다. (predict)

정리하자면 데이터를 모은 뒤,
이를 잘 설명하는 model을 정의하고 loss ftn을 정의한다.
loss ftn은 X, y, $\theta$의 함수이지만 X, y는 realized value이므로 결국 loss ftn은 $\theta$의 함수이다.
이 loss를 최소화하는  $\theta$를 찾는게 목적이지만 closed form으로 구할 수 없을 경우 GD같은 방법을 이용해 구한다.

deep learning에서 자주 사용되는 loss ftn은 MSE, cross entropy 두가지이다. 다른 loss도 많은데 왜 이 두가지가 자주 사용되는걸까?

딥러닝처럼 복잡한 모델에 대해서 학습을 할 때는 gradient descent를 구하기 위해서 필요한 gradient가 단순하게 구해지지 않는다.
layer를 통과할 때마다 구해지는 gradient의 곱을 이용해 back propagation 알고리즘을 이용해 weight update를 하게 되는데 back prop을 사용하기 위해서는 loss ftn에 두가지 제약이 따른다.
1. training DB의 전체 데이터에 대한 loss가 sample 데이터에 대한 loss의 합이다.
2. sample별 loss ftn의 입력인자는 label과 neural network의 출력값 두가지여야 한다.

이러한 제약을 만족시키는 mse, cross entropy와 같은 loss ftn이 backprop이 필요한 DNN에 자주 사용되는 것이다.

그렇다면 loss를 해석하는 두가지 관점에 대해서 생각해보자.

1. back prop 관점에서 해석

"loss를 줄이는 방향으로 업데이트"

L(y, $f_{\theta}(X)$)를 최소화하기 위해 backprop
cross entropy와 mse 중에서 cross entropy가 더 backprop이 더 잘된다.
(수식상 절묘하게 vanishing gradient에 강인)

2. mle 관점에서 해석

"네트워크 출력값을 미리 정해둔 분포의 파라미터로 해석"

$f_{\theta}(.)$ = 모델종류
$p(y|f_{\theta}(x))$ = 정해진 확률분포에서 출력(y)이 나올 확률, 출력값 $f_{\theta}(x)$ 은 정해진 확률분포의 모수로 해석할 수 있다.
예를 들어 정해진 확률분포가 정규분포라고 할 때, $f_{\theta1}(x) = 3$에서 $\theta$가 업데이트되어 $f_{\theta2}(x) = 5$가 될 경우, 정규분포의 평균이 3에서 5로 업데이트된 것으로 볼 수 있습니다.
이 때 y=6이라면 평균이 3인 정규분포보다는 5인 정규분포에서 뽑힌 값일 확률이 더 높으므로 올바른 방향으로 업데이트 된 것으로 생각할 수 있습니다.

![image](https://user-images.githubusercontent.com/85322951/205558953-7bc891e9-8e20-488f-81c2-687c403679e9.png)

이를 수식으로 나타내면, 
$\theta^* = argmin[-logp(y|f_{\theta}(x))]$로 볼 수 있다.
따라서 negative log likelihood를 최소화하는 $\theta$는 MLE로 볼 수 있다.

이때 $p(y|f_{\theta^*}(x))$는 우리가 찾은 $\theta^*$를 대입하여 구한 특정한 분포라고 할 수 있다. (정규분포, 베르누이분포 등)
따라서 이를 이용해서 새로운 값을 샘플링을 할 수 있다.

$y_{new}~p(y|f_{\theta^*}(x_{new}))$

즉 $x_{new}$를 $f_{\theta^*}(x_{new})$에 대입하더라도 deterministic하게 값이 결정되는 것이 아니라 해당 분포에서 값을 샘플링을 할 수 있다.

미리 정해진 분포는 가우시안 분포 또는 베르누이 분포로 정한다.
이를 수식으로 풀어보자.

1. 가우시안 분포

$f_{\theta}(x_i) = \mu_{i}, \sigma_{i} = 1$  
$p(y_{i}|\mu_{i},\sigma_{i}) = {1 \over \sqrt{2\pi} \sigma_{i}}{exp(-(y_{i}-\mu_{i})^2 \over {2\sigma_{i}^2})} $   
$logp(y_{i}|\mu_{i},\sigma_{i}) = log{1 \over \sqrt{2\pi} \sigma_{i}}-{(y_{i}-\mu_{i})^2 \over 2\sigma_{i}^2}$  
$-logp(y_{i}|\mu_{i}) = -log{1 \over \sqrt{2\pi}}-{(y_{i}-{\mu_{i})^2 \over 2}$  
$-logp(y_{i}|\mu_{i}) \propto {(y_{i}-\mu_{i})^2 \over 2 }= {(y_{i}-f_{\theta}(x_{i}))^2 \over 2}$  
