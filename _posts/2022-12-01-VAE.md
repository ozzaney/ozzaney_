---
layout: post
title:  "Variational AutoeEncoder is not an AutoEncoder"
categories: [ AI, MachineLearning ]
image: assets/images/vae_main.png
use_math: true
---

# 계속 나오는 VAE! 공부해보자

해당 포스트는 이활석님의 "오토인코더의 모든 것"강의를 정리한 포스트입니다.

## contents

1. revisit DNN
2. manifold learning
3. AutoEncoder
4. Variational AutoEncoder
5. Application

## AutoEncoder

AutoEncoder는 인공신경망 네트워크의 일종으로, 차원축소를 목적으로 데이터의 representation을 학습하기 위한 네트워크이다.
최근에는 AE 모델이 generative model분야에서 자주 사용된다고 한다. (그 이유는 이따가 알아봅시다.)

## 오토인코더의 구조
![AE](https://user-images.githubusercontent.com/85322951/204951758-b1bfb407-8baa-4912-9b40-0130db790376.png)

오토인코더는 다음과 같이 인코더와 디코더가 붙어 있는 구조를 갖고 있다.
오토인코더를 학습할 때는 비지도학습을 따르고 loss는 negative Maximum Likelihood로 해석된다.(뒷부분에서 자세히 설명)
학습완료 후 인코더는 차원축소 모델로 기능하고 디코더는 생성모델로 기능한다.

AutoEncoder에 대한 키워드는 4가지로 볼 수가 있다.

1. Unsupervised learing : 비지도학습, 즉 학습시 라벨링이 필요가 없다!
2. manifold learning: 고차원의 공간 전체에 중요한 정보가 있는게 아니다. 정보가 몰려 있는 manifold 공간을 찾아 차원을 축소시키자.
3. generative model learning: 모델 내 생성파트가 존재한다.
4. Maximum Likelihood density estimation: 우도를 최대화하는 density를 예측한다.

autoencoder를 본격적으로 들어가기 전 먼저 필요한 DNN에 대한 이해를 해보도록 하자.
(굳이 DNN에 대해서 다시 다루는 이유는 loss를 MLE관점에서 해석한다는 의미를 이해하기 위해서이다.)

## revisit DNN

고전적 머신러닝의 방법론을 순서대로 생각해보자. (비지도학습기준)
1. 먼저 데이터셋을 모은다. (X, y) 
2.  X를 가지고 y를 설명할 좋은 방법은 없을까? 가장 좋은 설명을 하는 model을 정의한다.
 $f_{\theta}()$
모델은 theta의 함수이다.
3. Loss는 target과 예측값의 차이이다. 원하는 Loss를 정의한다. 이때 Loss는 target과 model에 X를 대입한 값에 대한 함수이다.
4. learning 과정은 Loss를 최소화하는 $\theta$를 찾는 과정이다. 이때 closed form으로 argmin L이 주어지면 좋지만 그렇지 않을 경우 gradient descent 방법과 같은 iterative한 방법을 적용한다. 
5. 4번 과정을 통해 얻은 최적의 $\theta$를 f에 대입하여 최종 모델을 얻는다. model에 새로운 x데이터를 대입한 $f_{\theta}$가 $y_{new}$와 가까운지를 본다. (predict)

정리하자면 데이터를 모은 뒤,
이를 잘 설명하는 model을 정의하고 loss ftn을 정의한다.
loss ftn은 X, y, $\theta$의 함수이지만 X, y는 realized value이므로 결국 loss ftn은 $\theta$의 함수이다.
이 loss를 최소화하는  $\theta$를 찾는게 목적이지만 closed form으로 구할 수 없을 경우 GD같은 방법을 이용해 구한다.

deep learning에서 자주 사용되는 loss ftn은 MSE, cross entropy 두가지이다. 다른 loss도 많은데 왜 이 두가지가 자주 사용되는걸까?

딥러닝처럼 복잡한 모델에 대해서 학습을 할 때는 gradient descent를 구하기 위해서 필요한 gradient가 단순하게 구해지지 않는다.
layer를 통과할 때마다 구해지는 gradient의 곱을 이용해 back propagation 알고리즘을 이용해 weight update를 하게 되는데 back prop을 사용하기 위해서는 loss ftn에 두가지 제약이 따른다.
1. training DB의 전체 데이터에 대한 loss가 sample 데이터에 대한 loss의 합이다.
2. sample별 loss ftn의 입력인자는 label과 neural network의 출력값 두가지여야 한다.

이러한 제약을 만족시키는 mse, cross entropy와 같은 loss ftn이 backprop이 필요한 DNN에 자주 사용되는 것이다.

### loss를 해석하는 두가지 관점

그렇다면 loss를 해석하는 두가지 관점에 대해서 생각해보자.

1 back prop 관점에서 해석

"loss를 줄이는 방향으로 업데이트"

$L(y, f_{\theta}(x) )$를 최소화하기 위해 backprop
cross entropy와 mse 중에서 cross entropy가 더 backprop이 더 잘된다.
(수식상 절묘하게 vanishing gradient에 강인)

2 mle 관점에서 해석

"네트워크 출력값을 미리 정해둔 분포의 파라미터로 해석"

$f_{\theta}(.)$ = 모델종류
$p(y|f_{\theta}(x))$ = 정해진 확률분포에서 출력(y)이 나올 확률, 출력값 $f_{\theta}(x)$ 은 정해진 확률분포의 모수로 해석할 수 있다.
예를 들어 정해진 확률분포가 정규분포라고 할 때, $f_{\theta1}(x) = 3$에서 $\theta$가 업데이트되어 $f_{\theta2}(x) = 5$가 될 경우, 정규분포의 평균이 3에서 5로 업데이트된 것으로 볼 수 있습니다.
이 때 y=6이라면 평균이 3인 정규분포보다는 5인 정규분포에서 뽑힌 값일 확률이 더 높으므로 올바른 방향으로 업데이트 된 것으로 생각할 수 있습니다.

![image](https://user-images.githubusercontent.com/85322951/205558953-7bc891e9-8e20-488f-81c2-687c403679e9.png)

이를 수식으로 나타내면, 
$\theta^* = argmin[-logp(y|f_{\theta}(x))]$로 볼 수 있다.
따라서 negative log likelihood를 최소화하는 $\theta$는 MLE로 볼 수 있다.

이때 $p(y|f_{ \theta^* }(x))$는 최적의 $\theta^* $를 대입하여 구한 특정한 분포라고 할 수 있다. (정규분포, 베르누이분포 등) 따라서 이를 이용해서 새로운 값을 샘플링을 할 수 있다.

$y_{new}~p(y|f_{\theta^*}(x_{new}))$

즉 $x_{new}$를 $f_{\theta^*}(x_{new})$에 대입하더라도 deterministic하게 값이 결정되는 것이 아니라 해당 분포에서 값을 샘플링을 할 수 있다.

미리 정해진 분포는 가우시안 분포 또는 베르누이 분포로 정한다.
이를 수식으로 풀어보자.

1. 가우시안 분포: Mean Square Error

$f_{\theta}(x_i) = \mu_{i}, \sigma_{i} = 1$  
$p(y_{i}|\mu_{i},\sigma_{i}) = {1 \over \sqrt{2\pi} \sigma_{i}}exp{-(y_{i}-\mu_{i})^2 \over {2\sigma_{i}^2}} $     
$logp(y_{i}|\mu_{i},\sigma_{i}) = log{1 \over \sqrt{2\pi} \sigma_{i}}-{(y_{i}-\mu_{i})^2 \over 2\sigma_{i}^2}$  
$-logp(y_{i}|\mu_{i}) = -log{1 \over \sqrt{2\pi}}+{(y_{i}-\mu_{i})^2 \over 2}$  
$-logp(y_{i}|\mu_{i}) \propto {(y_{i}-\mu_{i})^2 \over 2 }= {(y_{i}-f_{\theta}(x_{i}))^2 \over 2}$  

y의 분포를 정규분포로 가정하고 negative log likelihhood를 최소화하는 과정은 결국 mean square error를 최소화하는 과정과 똑같다.

2. 베르누이 분포: cross-entropy  

$p(y_{i}|p_{i}) = p_{i}^{y_{i}}(1-p_{i})^{1-y_{i}}$       
$log(p(y_{i}|p_{i})) = y_{i}log(p_{i})+(1-y_{i})log(1-p_{i})$   
$-log(p(y_{i}|p_{i})) = -[y_{i}log(p_{i})+(1-y_{i})log(1-p_{i})]$  

y의 분포를 베르누이로 가정하고 negative log likelihhood를 최소화하는 것은 cross entropy를 최소화하는 것과 같다.

이러한 이유로 연속확률분포에 대해서는 mse를 loss ftn으로 사용하고 이산확률분포에서는 cross entropy를 loss ftn으로 사용하는 것이 자연스럽다.

autoencoder: p(x|x)
입력과 출력이 동일하므로, p(x|x)를 추정

variational autoencoder: p(x)
given이 없이 trainingDB의 확률분포를 추정

## manifold learning

고차원데이터는 training db의 차원 그 자체인데, 이를 데이터 공간에 쫙 뿌렸을 때 이러한 데이터를 잘 아우르는 subspace를 manifold라고 한다. manifold를 찾고 그 위로 데이터를 정사영한다면 데이터의 정보를 많이 잃지 않고도 차원을 줄일 수 있다.
이러한 차원축소를 왜 해야하는 것일까?

1. 데이터 압축 
2. 데이터 시각화
3. 차원의 저주 극복
4. 중요한 features 찾기 

[manifold hypothesis]
- 고차원의 데이터는 밀도가 낮지만 이들의 집합을 포함하는 저차원의 manifold가 있다.
- 이 저차원의 manifold를 벗어나는 순간 밀도가 급격히 낮아진다. 

만약 manifold 가정이 사실이 아니라면 유니폼 샘플링했을 때 의미있는 데이터가 도출되어야 한다.
그러나 현실에서 유니폼 샘플링을 해보면 거의 대부분 노이즈가 도출된다.
매니폴드를 잘 찾으면 서로 다른데 비슷한 데이터간의 관계를 알아낼 수 있다.
매니폴드 학습 결과를 평가하기 위해 매니폴드 좌표들이 조금씩 변할 때 원데이터도 유의미하게 조금씩 변한다.

[resonable distance metric]

원래 데이터 공간에서의 유클리디안 거리가 가까운 대상과 메니폴드상에서의 유클리디안 거리가 가까운 대상이 다르다.
메니폴드 상에서 유클리디안이 가깝다는 뜻은 dominant한 feature들끼리 가깝다는 뜻으로, 
의미상 가까운 대상일 가능성이 높다. 반대로 원래 데이터 공간에서 가까워도 의미적으로 가깝지 않은 대상일 가능성이 높다.

## Autoencoder 

인코더 파트에서는 차원이 줄어들고, 디코더 파트에서는 차원이 늘어난다.
