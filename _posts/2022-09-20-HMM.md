---
layout: post
title:  "HMM..."
categories: [ AI, NLP, ML]
image: assets/images/hmm.png
use_math: true
---

# Hidden Markov Model, modeling sequence data

해당 포스트는 [hmm 강의](https://www.youtube.com/watch?v=HB9Nb0odPRs&t=2s)의 요약입니다. 자세한 내용은 강의를 확인해주세요.

HMM은 **sequence data**의 분포를 학습해 확률적으로 모델링하는 [생성모델](https://danbi-ncsoft.github.io/works/2021/10/01/Generator.html)입니다.

이 모델이 해결할 수 있는 문제들이 무엇인지를 살펴보며 흥미를 돋워 보겠습니다.

- 특정인의 행동에 따른 날씨 추측
- 떡볶이 소비량에 따른 날씨 추측
- DNA 염기서열에서 어느부분이 유전자인지 추측
- 주어진 단어의 품사 추측

딱 보니까 **두개의 sequence 데이터**를 이렇게 저렇게 해서 원하는 추측을 해내는 모델인 것을 알 수 있습니다. 
그렇다면 HMM이 무엇인지 자세히 알아볼까요?

먼저 Markov model에 대해 자세히 알아봅시다.

## 1. Markov model

markov model은 markov가정하에 state로 이루어진 sequence를 state transition probability matrix(상태전이확률행렬)로 표현한 것입니다.
markov 가정은 시간 t에서의 관측은 가장 최근 r개의 관측에만 의존한다는 가정으로 한 상태에서 다른 상태로의 전이는 이전 상태의 긴 이력이 필요하지 않다는 가정입니다.
이를 수식으로 나타내면 r=1일 때, $P(S_t|S_{t-1},S_{t-2},S_{t-3},...)=P(S_t|S_{t-1})$과 같습니다.

이제 r=1인 markov model의 예를 들어보겠습니다.
state = {해, 비}
s = [비, 해, 해, 해, 비, 비, 해]
위 예시에서 state는 두가지로 해, 비가 있으며, 이러한 state로 이루어진 sequnce s가 있습니다.
이때 상태전이확률행렬을 만들어봅시다.
총 6번의 transition 중 비에서 해로 넘어가는 것은 2번, 비에서 비는 1번, 해에서 해는 2번, 해에서 비는 1번이므로,
state transition probability matrix는
$$ \left[
\begin{matrix}
    1/3 & 2/3 \\
    1/3 & 2/3  \\
\end{matrix}
\right] $$
입니다. (이때 1행1열 비->비, 1행2열 비->해, 2행1열 해->비, 2행2열 해->해을 의미합니다.)
